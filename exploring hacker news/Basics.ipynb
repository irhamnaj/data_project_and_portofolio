{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "today, i will exploring hacker news dataset,\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "hacker news dataset is summary of the hacker newst post, which is contain many information, such as number point of upvote, title, url, number of comments, author and many more.\n",
    "\n",
    "This dataset will be analyzed to know more about pattern in dataset and also answer many question, such as Do posts created at a certain time receive more comments on average?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['12224879',\n",
       "  'Interactive Dynamic Video',\n",
       "  'http://www.interactivedynamicvideo.com/',\n",
       "  '386',\n",
       "  '52',\n",
       "  'ne0phyte',\n",
       "  '8/4/2016 11:52'],\n",
       " ['10975351',\n",
       "  'How to Use Open Source and Shut the Fuck Up at the Same Time',\n",
       "  'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/',\n",
       "  '39',\n",
       "  '10',\n",
       "  'josep2',\n",
       "  '1/26/2016 19:30'],\n",
       " ['11964716',\n",
       "  \"Florida DJs May Face Felony for April Fools' Water Joke\",\n",
       "  'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/',\n",
       "  '2',\n",
       "  '1',\n",
       "  'vezycash',\n",
       "  '6/23/2016 22:20'],\n",
       " ['11919867',\n",
       "  'Technology ventures: From Idea to Enterprise',\n",
       "  'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429',\n",
       "  '3',\n",
       "  '1',\n",
       "  'hswarna',\n",
       "  '6/17/2016 0:01'],\n",
       " ['10301696',\n",
       "  'Note by Note: The Making of Steinway L1037 (2007)',\n",
       "  'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0',\n",
       "  '8',\n",
       "  '2',\n",
       "  'walterbell',\n",
       "  '9/30/2015 4:12']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to import dataset\n",
    "from csv import reader\n",
    "\n",
    "#open and read data using open and read function\n",
    "def read_data(dataset, header = True):\n",
    "    opened_data = open(dataset)\n",
    "    reader_data = reader(opened_data)\n",
    "    \n",
    "    #make data become list\n",
    "    new_data = list(reader_data)\n",
    "    \n",
    "    #print header in distinct list\n",
    "    if header :\n",
    "        return new_data[0], new_data[1:]\n",
    "    \n",
    "    return new_data\n",
    "\n",
    "data_hacker_header, data_hacker = read_data('hacker_news.csv')\n",
    "\n",
    "data_hacker[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hacker_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " for this analyst we focus on post with title Ask Hn adn Show Hn,\n",
    " \n",
    " 1. Ask Hn  are the posts to ask the Hacker News community a specific question, for instance \"Ask HN: How to improve my personal website?\"\n",
    " 2. Show Hn are the posts to show the Hacker News community a project, product, or just generally something interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "#extract row with ask hn and show hn\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "#loop the data\n",
    "for row in data_hacker:\n",
    "    title = row[1]\n",
    "    title_lower = title.lower() #change title become lower, to make easy for analyst\n",
    "    if title_lower.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title_lower.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from function above, i find that 1744 post begin with ask_posts and 1162 post begin with show_posts,\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask Posts and Comments by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this section, we'll determine if ask posts created at a certain time are more likely to attract comments\n",
    "there are two steps to get the analysis:\n",
    "1. find total number of comment per hour\n",
    "2. find average amount of comment per hour\n",
    "\n",
    "but, before we do analysis let's find total number comments between ask_posts and show_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_comments\n",
      "total_ask_comments:  24483\n",
      "avg_ask_comments:  14.038417431192661\n",
      "\n",
      "\n",
      "shows_comments\n",
      "total_show_comments:  11988\n",
      "avg_show_comments:  10.31669535283993\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find total number of comment in ask_posts\n",
    "total_ask_comments = 0\n",
    "\n",
    "#loop the data\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "#calculate average\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print('ask_comments')\n",
    "print('total_ask_comments: ', total_ask_comments)\n",
    "print('avg_ask_comments: ' , avg_ask_comments)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#find total number of comment in show_posts\n",
    "total_show_comments = 0\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments /len(show_posts)\n",
    "\n",
    "print('shows_comments')\n",
    "print('total_show_comments: ', total_show_comments)\n",
    "print('avg_show_comments: ', avg_show_comments)\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from my findings, people are likely more comments on ask posts rather than shows comments, let's see more deeply in ask_posts using 2 point which are created in the beginning of section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#amount of ask posts and comment per hours\n",
    "import datetime as dt\n",
    "\n",
    "#make empty list\n",
    "result_list = []\n",
    "\n",
    "#loop ask_posts\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    n_comments = int(row[4])\n",
    "    result_list.append([created_at, n_comments])\n",
    "    \n",
    "#make dictionary for count comment per hours\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "date_format = '%m/%d/%Y %H:%M'\n",
    "\n",
    "#loop the data\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    number_comments = int(row[1])\n",
    "    date_strip = dt.datetime.strptime(date, date_format) #change the date using datetime function\n",
    "    hour = date_strip.strftime('%H')\n",
    "    \n",
    "    #loop the data\n",
    "    if hour not in counts_by_hour :\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = number_comments\n",
    "    elif hour in counts_by_hour:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += number_comments\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculating the average comments per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculating average \n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for data in counts_by_hour:\n",
    "    avg_by_hour.append([data, comments_by_hour[data]/counts_by_hour[data]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to make easy analysis, sorted the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 hours for ask post comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "#swap the data\n",
    "swap_avg_by_hour = []\n",
    "for rows in avg_by_hour:\n",
    "    swap_avg_by_hour.append([rows[1], rows[0]])\n",
    " \n",
    "#sorted the data\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "print('top 5 hours for ask post comments')\n",
    "\n",
    "for avg, hour in sorted_swap[0:5]:\n",
    "    date_strip = dt.datetime.strptime(hour, '%H')\n",
    "    format_hour = date_strip.strftime('%H:%M:')\n",
    "    average = avg\n",
    "    print('{0} {1:.2f} average comments per post'.format(format_hour, average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from this analyst, we know that highest average comment in ask post it's happen in the afternoon, between 15:00 and 16:00 and in the evening, between 20:00 - 21:00 and 02:00.\n",
    "\n",
    "if we compare with the office hours, most of people comment in ask section ehen people doesn't have working hours such as when in the road or in the cofee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hacker_header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the average point of ask_post and show_post"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " i will try to finding the average point of both post and compare it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_points\n",
      "total_ask_points :  26268.0\n",
      "avg_ask_points :  15.061926605504587\n",
      "\n",
      "\n",
      "shows_points\n",
      "total_show_points:  32019.0\n",
      "avg_show_points:  27.555077452667813\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#average ask_post\n",
    "total_ask_points = 0\n",
    "\n",
    "#loop the data\n",
    "for row in ask_posts:\n",
    "    num_points = float(row[3])\n",
    "    total_ask_points += num_points\n",
    "\n",
    "#calculate average\n",
    "avg_ask_points = total_ask_points / len(ask_posts)\n",
    "\n",
    "print('ask_points')\n",
    "print('total_ask_points : ', total_ask_points)\n",
    "print('avg_ask_points : ', avg_ask_points)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "#find total number of points in show_posts\n",
    "total_show_points = 0\n",
    "for row in show_posts:\n",
    "    num_points = float(row[3])\n",
    "    total_show_points += num_points\n",
    "    \n",
    "avg_show_points = total_show_points /len(show_posts)\n",
    "\n",
    "print('shows_points')\n",
    "print('total_show_points: ', total_show_points)\n",
    "print('avg_show_points: ', avg_show_points)\n",
    "print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from function above, i find that show_post have higher points than ask_points, \n",
    "\n",
    "for the next analysis, i will find average and total points between 2 posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Amount of Ask_posts points by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same as comment section, i will try finding the amount and average of both posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make function to find top 5 amount and average of points\n",
    "\n",
    "def top_5(dataset, name_dataset):\n",
    "    import datetime as dt\n",
    "\n",
    "    #make empty list\n",
    "    result_list = []\n",
    "\n",
    "    #loop dataset\n",
    "    for row in dataset:\n",
    "        created_at = row[6]\n",
    "        n_points = float(row[3])\n",
    "        result_list.append([created_at, n_points])\n",
    "    \n",
    "    #make dictionary for count comment per hours\n",
    "    counts_by_hour = {}\n",
    "    points_by_hour = {}\n",
    "    date_format = '%m/%d/%Y %H:%M'\n",
    "\n",
    "    #loop the data\n",
    "    for row in result_list:\n",
    "        date = row[0]\n",
    "        number_points = float(row[1])\n",
    "        date_strip = dt.datetime.strptime(date, date_format) #change the date using datetime function\n",
    "        hour = date_strip.strftime('%H')\n",
    "    \n",
    "        #loop the data\n",
    "        if hour not in counts_by_hour :\n",
    "            counts_by_hour[hour] = 1\n",
    "            points_by_hour[hour] = number_points\n",
    "        elif hour in counts_by_hour:\n",
    "            counts_by_hour[hour] += 1\n",
    "            points_by_hour[hour] += number_points\n",
    "            \n",
    "    #calculating average \n",
    "    avg_by_hour = []\n",
    "\n",
    "    for data in counts_by_hour:\n",
    "        avg_by_hour.append([data, points_by_hour[data]/counts_by_hour[data]])\n",
    "        \n",
    "    #swap the data\n",
    "    swap_avg_by_hour = []\n",
    "    for rows in avg_by_hour:\n",
    "        swap_avg_by_hour.append([rows[1], rows[0]])\n",
    " \n",
    "    #sorted the data\n",
    "    sorted_swap = sorted(swap_avg_by_hour, reverse = True)\n",
    "\n",
    "    print('top 5 hours for {0} dataset'.format(name_dataset))\n",
    "\n",
    "    for avg, hour in sorted_swap[0:5]:\n",
    "        date_strip = dt.datetime.strptime(hour, '%H')\n",
    "        format_hour = date_strip.strftime('%H:%M:')\n",
    "        average = avg\n",
    "        print('{0} {1:.2f} average points per post'.format(format_hour, average))\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 hours for show_posts dataset\n",
      "23:00: 42.39 average points per post\n",
      "12:00: 41.69 average points per post\n",
      "22:00: 40.35 average points per post\n",
      "00:00: 37.84 average points per post\n",
      "18:00: 36.31 average points per post\n"
     ]
    }
   ],
   "source": [
    "top_5(show_posts, 'show_posts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 hours for ask_posts dataset\n",
      "15:00: 29.99 average points per post\n",
      "13:00: 24.26 average points per post\n",
      "16:00: 23.35 average points per post\n",
      "17:00: 19.41 average points per post\n",
      "10:00: 18.68 average points per post\n"
     ]
    }
   ],
   "source": [
    "top_5(ask_posts, 'ask_posts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we find that in show_posts, the high average points was happend in night and afternoon and it different with ask_posts.\n",
    "\n",
    "in ask_post, most points came from afternoon time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the conclusion, all analysis give insight that many of people read post in hacker news in the time when they're not work or out of working hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
